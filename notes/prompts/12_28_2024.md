## 12/29/24

We enhanced our Kubernetes operator to properly deploy and configure kube-state-metrics alongside Prometheus. First, we set up comprehensive Prometheus configuration to scrape various metrics from the cluster, including API server, nodes, pods, and the kube-state-metrics service itself. Then, we implemented the necessary controller logic to deploy kube-state-metrics using a Deployment and Service. Most importantly, we added proper RBAC configurations that give kube-state-metrics the permissions it needs to read metrics from various cluster resources. This includes permissions to monitor pods, deployments, jobs, and other Kubernetes objects. The end result is a more complete monitoring solution where Prometheus can collect rich metrics about the state of your Kubernetes cluster through kube-state-metrics, allowing for better observability of your cluster's resources and workloads.

Here's the testing sequence you should follow after making these changes:

1. First, rebuild and reinstall the operator components:
```bash
# Generate the new RBAC manifests and CRDs
make manifests

# Install the updated CRDs
make install

# Run the operator locally
make run
```

2. In another terminal, apply your CR:
```bash
kubectl delete -f config/samples/monitoring_v1alpha1_observabilitystack.yaml
```
```bash
kubectl apply -f config/samples/monitoring_v1alpha1_observabilitystack.yaml
```

3. Verify the resources were created:
```bash
# Check kube-state-metrics resources
kubectl get deployment -l app.kubernetes.io/name=kube-state-metrics
kubectl get service -l app.kubernetes.io/name=kube-state-metrics
kubectl get serviceaccount -l app.kubernetes.io/name=kube-state-metrics
kubectl get clusterrole,clusterrolebinding -l app.kubernetes.io/name=kube-state-metrics

# Check Prometheus
kubectl get statefulset,svc -l app.kubernetes.io/name=prometheus
```

4. Verify metrics collection:
```bash
# Port-forward Prometheus
kubectl port-forward svc/monitoring-test-prometheus 9090:9090
```

Then visit http://localhost:9090/targets in your browser - you should see kube-state-metrics listed as one of the scrape targets, and it should be in an "Up" state.

Would you like me to show you some useful PromQL queries to test the kube-state-metrics data collection?


Here are some useful PromQL queries categorized by what they monitor:

```markdown
# Useful Prometheus Queries

### Pod Metrics
```promql
# List all running pods
kube_pod_status_phase{phase="Running"}

# Pod restarts
kube_pod_container_status_restarts_total

# Pod resource requests and limits
kube_pod_container_resource_requests
kube_pod_container_resource_limits
```

### Node Metrics
```promql
# Node CPU usage
node_cpu_seconds_total

# Node memory usage
node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes

# Node disk usage
node_filesystem_avail_bytes
```

### Container Metrics
```promql
# Container CPU usage rate
rate(container_cpu_usage_seconds_total{container!=""}[5m])

# Container memory usage
container_memory_usage_bytes{container!=""}

# Container network traffic
rate(container_network_receive_bytes_total[5m])
rate(container_network_transmit_bytes_total[5m])
```

### Kubernetes State Metrics
```promql
# Deployment status
kube_deployment_status_replicas_available

# Pod status by namespace
sum by (namespace) (kube_pod_status_phase)

# PVC usage
kube_persistentvolumeclaim_resource_requests_storage_bytes
```

### Service Metrics
```promql
# HTTP request rate
rate(http_requests_total[5m])

# Error rate
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
```

These queries can help monitor:
- Resource usage across your cluster
- Application health and performance
- System bottlenecks
- Error rates and potential issues


## new setup


Let's test the changes in order:

1. First, make sure everything is cleaned up:
```bash
kubectl delete -f config/samples/monitoring_v1alpha1_observabilitystack.yaml
kubectl delete pvc --all
```

2. Apply the changes:
```bash
make manifests
make install
make run
```

3. In another terminal, apply the CR:
```bash
kubectl apply -f config/samples/monitoring_v1alpha1_observabilitystack.yaml
```

4. Check if everything is running:
```bash
kubectl get pods
kubectl get pvc
kubectl get svc
```

5. If all looks good, port-forward both services:
```bash
# In one terminal:
kubectl port-forward svc/monitoring-test-prometheus 9090:9090

# In another terminal:
kubectl port-forward svc/monitoring-test-grafana 3000:3000
```

6. Visit in browser:
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (login with admin/admin)

Would you like me to help you set up the Grafana dashboards once you confirm everything is running?

## Problems with complexity

Here's a comprehensive project structure for a Helm-based observability deployment:

```
observability-stack/
│
├── charts/                 # Helm chart configurations
│   ├── prometheus/
│   │   ├── Chart.yaml
│   │   └── values.yaml
│   ├── grafana/
│   │   ├── Chart.yaml
│   │   └── values.yaml
│   ├── loki/
│   │   ├── Chart.yaml
│   │   └── values.yaml
│   └── tempo/
│       ├── Chart.yaml
│       └── values.yaml
│
├── dashboard/              # Optional React dashboard
│   ├── src/
│   │   ├── components/
│   │   │   └── ObservabilityOverview.js
│   │   ├── pages/
│   │   │   └── DashboardPage.js
│   │   └── services/
│   │       └── observabilityService.js
│   ├── package.json
│   └── README.md
│
├── scripts/                # Deployment and management scripts
│   ├── install.sh
│   ├── uninstall.sh
│   └── update.sh
│
├── k8s/                    # Kubernetes-specific configs
│   ├── namespace.yaml
│   └── network-policies.yaml
│
├── values.yaml             # Global configuration
├── Chart.yaml              # Main chart definition
├── README.md
└── .github/                # CI/CD workflows
    └── workflows/
        ├── deploy.yml
        └── validate.yml
```

### Detailed Configuration Example

#### Root `values.yaml`
```yaml
global:
  observabilityNamespace: monitoring

prometheus:
  enabled: true
  retention: 15d
  storageSize: 50Gi

grafana:
  enabled: true
  adminPassword: ${GRAFANA_ADMIN_PASSWORD}
  datasources:
    - name: Prometheus
      type: prometheus
    - name: Loki
      type: loki

loki:
  enabled: true
  storage: 100Gi
  retention: 7d

tempo:
  enabled: true
  storage: 50Gi
  samplingRate: 0.1
```

#### Individual Chart Configuration
Each chart in `charts/` would have its own `values.yaml` and `Chart.yaml` for specific configurations.

### Dashboard Integration
The React dashboard could:
- Fetch metrics from Prometheus
- Display logs from Loki
- Show traces from Tempo
- Provide unified observability view

### Deployment Options

1. **Helm Installation**
```bash
helm install observability . \
  --namespace monitoring \
  --create-namespace
```

2. **ArgoCD Deployment**
```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: observability-stack
spec:
  source:
    repoURL: 'https://github.com/your-repo'
    path: observability-stack
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
```

### Benefits of This Approach
- Modular configuration
- Easy to customize
- Supports multiple deployment methods
- Separation of concerns
- Scalable architecture

### Potential Enhancements
- Add Prometheus Operator integration
- Create custom dashboards
- Implement advanced filtering
- Add cost optimization insights

Would you like me to elaborate on any part of this structure or discuss implementation details?